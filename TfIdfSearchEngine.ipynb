{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0feb3c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, math\n",
    "import numpy as np\n",
    "from lxml import etree\n",
    "from stemming.porter2 import stem\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da02e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_func (doc_id=\"query\",text_list):\n",
    "    tf_dict = {}\n",
    "    x = Counter(text_list)\n",
    "    max_occurence = x.most_common(1)[0][1]\n",
    "    x = dict(sorted(x.items()))\n",
    "    \n",
    "    for word, count in x.items():\n",
    "        tf = count/max_occurence\n",
    "        tf_dict[doc_id].update({word,tf})\n",
    "    return tf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f287b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "collectionName = \"nytsmall\"\n",
    "#collectionName = \"nyt199501\"\n",
    "\n",
    "tree = etree.parse( collectionName + \".xml\")\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac74b874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4a21987edd4941a8c336b247ebbe96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab = {}\n",
    "corpus = {}\n",
    "\n",
    "\n",
    "for doc in tqdm(root.iter('DOC')):\n",
    "    doc_txt = \"\"\n",
    "    for element in doc.iter('HEADLINE', \"P\", \"TEXT\"):\n",
    "        doc_txt += element.text\n",
    "    doc_txt = doc_txt.translate(str.maketrans(\n",
    "        '', '', string.punctuation)).lower()\n",
    "    doc_txt = list(map(stem, doc_txt.split()))\n",
    "    \n",
    "    for word in set(doc_txt):\n",
    "        if word not in vocab:\n",
    "            vocab[word] = 1\n",
    "        else:\n",
    "            vocab[word] += 1\n",
    "            \n",
    "    corpus[doc.attrib['id']] = doc_txt\n",
    "vocab = dict(sorted(vocab.items()))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbc88bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b39265d5a6c47578813108c936efacc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sorting corpus dict\n",
    "corpus = dict(sorted(corpus.items()))\n",
    "n_docs = len(corpus)\n",
    "\n",
    "idf_dict = {}\n",
    "\n",
    "# IDF\n",
    "with open (collectionName + '.idf', 'w') as file:\n",
    "    for term, count in tqdm(vocab.items()):\n",
    "        idf = math.log(n_docs/count)\n",
    "        idf_dict[term] = idf\n",
    "        file.write('{}\\t{}\\n'.format(term,idf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97e2c4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0e5e971b2e4f979f2660a69d870d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TF\n",
    "tf_dict = {}\n",
    "with open(collectionName+\".tf\",\"w\") as file:\n",
    "    for doc, text in tqdm(corpus.items()):\n",
    "        x = Counter(text)\n",
    "        max_occurence = x.most_common(1)[0][1]\n",
    "        x = dict(sorted(x.items()))\n",
    "\n",
    "        tf_dict[doc] = {}\n",
    "        for word, count in x.items():\n",
    "            tf = count/max_occurence\n",
    "            tf_dict[doc].update({word:tf})\n",
    "            file.write('{}\\t{}\\t{}\\n'.format(doc,word,tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3046354",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = {}\n",
    "\n",
    "word_to_ix = {key:value for key,value in zip(vocab.keys(),range(len(vocab)))}\n",
    "\n",
    "for doc_id,text in corpus.items():\n",
    "    tf_idf[doc_id] = np.zeros(len(vocab))   \n",
    "    \n",
    "    for term in text:\n",
    "        \n",
    "        tf_idf[doc_id][word_to_ix[term]] = tf_dict[doc_id][term] *idf_dict[term]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ea76ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.597882657212608\n"
     ]
    }
   ],
   "source": [
    "def tf_func (doc_id=\"query\",text_list):\n",
    "    tf_dict = {}\n",
    "    x = Counter(text)\n",
    "    max_occurence = x.most_common(1)[0][1]\n",
    "    x = dict(sorted(x.items()))\n",
    "    \n",
    "    for word, count in x.items():\n",
    "        tf = count/max_occurence\n",
    "        tf_dict[doc_id].update({word,tf})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db25e997",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ['hurricane', 'philadelphia']\n",
    "top10 = []\n",
    "\n",
    "for doc_id, text in corpus.items():\n",
    "    tf_idf_current = np.zeros(len(vocab))\n",
    "\n",
    "    \n",
    "    x = Counter(text)\n",
    "    max_occurence = x.most_common(1)[0][1]\n",
    "    x = dict(sorted(x.items()))\n",
    "    \n",
    "    for word,count in x.items():\n",
    "        tf = count/max_occurence\n",
    "    \n",
    "    for term in text:\n",
    "        tf_idf_current[word_to_ix[\n",
    "            term]] = tf_dict[doc_id][term] * idf_dict[term]\n",
    "\n",
    "\n",
    "\n",
    "# doc_txt = list(map(stem, doc_txt.split()))\n",
    "# doc_txt = doc_txt.translate(str.maketrans('', '', string.punctuation))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
