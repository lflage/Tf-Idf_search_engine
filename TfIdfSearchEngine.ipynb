{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34ef1379",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "- Create functions\n",
    "- refactor code with functions\n",
    "- Apply to python file\n",
    "- Create command line tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0feb3c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, math\n",
    "import numpy as np\n",
    "from lxml import etree\n",
    "from stemming.porter2 import stem\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7da02e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(txt:str) -> list:\n",
    "    \"\"\"Receives a string of text, removes the punctuation, turns text into \n",
    "    lowercase and performs stemming. Returns the input string as a list of \n",
    "    tokens\"\"\"\n",
    "    txt = txt.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    txt = list(map(stem, txt.split()))\n",
    "    return txt\n",
    "\n",
    "def tf_func (doc_id: str,text_list: list) -> dict:\n",
    "    \"\"\"Returns a dictionary containing the word the its term frequency\"\"\"\n",
    "    tf_dict = {}\n",
    "    x = Counter(text_list)\n",
    "    max_occurence = x.most_common(1)[0][1]\n",
    "    x = dict(sorted(x.items()))\n",
    "    \n",
    "    for word, count in x.items():\n",
    "        tf = count/max_occurence\n",
    "        tf_dict[doc_id].update({word,tf})\n",
    "    return tf_dict\n",
    "\n",
    "def idf_func(corpus:dict) -> dict:\n",
    "    \"\"\"Function to calculate IDF over corpus dict. The corpus dict is a dict\n",
    "    that contains the doc IDs as keys and the text as a list of tokens in its\n",
    "    values\"\"\"\n",
    "    idf_dict = {}\n",
    "    n_docs = len(corpus)\n",
    "    for term,count in corpus.items():\n",
    "        idf = math.log(n_docs/count)\n",
    "        idf_dict[term] = idf\n",
    "    return idf_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53f287b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "collectionName = \"nytsmall\"\n",
    "#collectionName = \"nyt199501\"\n",
    "\n",
    "tree = etree.parse( collectionName + \".xml\")\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac74b874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801b29a1cdd8431487c82f39cd4eb31f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab = {}\n",
    "corpus = {}\n",
    "\n",
    "\n",
    "for doc in tqdm(root.iter('DOC')):\n",
    "    doc_txt = \"\"\n",
    "    for element in doc.iter('HEADLINE', \"P\", \"TEXT\"):\n",
    "        doc_txt += element.text\n",
    "\n",
    "    # Pre Process\n",
    "    doc_txt = pre_process(doc_txt)\n",
    "    \n",
    "    # Creating vocab dict\n",
    "    for word in set(doc_txt):\n",
    "        if word not in vocab:\n",
    "            vocab[word] = 1\n",
    "        else:\n",
    "            vocab[word] += 1\n",
    "            \n",
    "    # Creating corpus dict\n",
    "    corpus[doc.attrib['id']] = doc_txt\n",
    "vocab = dict(sorted(vocab.items()))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbc88bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b3ea67a85e4c09b862dec8da58e2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sorting corpus dict\n",
    "corpus = dict(sorted(corpus.items()))\n",
    "n_docs = len(corpus)\n",
    "\n",
    "idf_dict = {}\n",
    "\n",
    "# IDF\n",
    "with open (collectionName + '.idf', 'w') as file:\n",
    "    for term, count in tqdm(vocab.items()):\n",
    "        idf = math.log(n_docs/count)\n",
    "        idf_dict[term] = idf\n",
    "        file.write('{}\\t{}\\n'.format(term,idf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97e2c4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a99cda36eb45d9b198a82f1946d2dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TF\n",
    "tf_dict = {}\n",
    "with open(collectionName+\".tf\",\"w\") as file:\n",
    "    for doc, text in tqdm(corpus.items()):\n",
    "        x = Counter(text)\n",
    "        max_occurence = x.most_common(1)[0][1]\n",
    "        x = dict(sorted(x.items()))\n",
    "\n",
    "        tf_dict[doc] = {}\n",
    "        for word, count in x.items():\n",
    "            tf = count/max_occurence\n",
    "            tf_dict[doc].update({word:tf})\n",
    "            file.write('{}\\t{}\\t{}\\n'.format(doc,word,tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3046354",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = {}\n",
    "\n",
    "word_to_ix = {key:value for key,value in zip(vocab.keys(),range(len(vocab)))}\n",
    "\n",
    "for doc_id,text in corpus.items():\n",
    "    tf_idf[doc_id] = np.zeros(len(vocab))   \n",
    "    \n",
    "    for term in text:\n",
    "        \n",
    "        tf_idf[doc_id][word_to_ix[term]] = tf_dict[doc_id][term] *idf_dict[term]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db25e997",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ['hurricane', 'philadelphia']\n",
    "\n",
    "\n",
    "# pre process query:\n",
    "query_str = \" \".join(query)\n",
    "query_str  = query_str.translate(str.maketrans(\n",
    "        '', '', string.punctuation)).lower()\n",
    "query = list(map(stem, query_str.split()))\n",
    "\n",
    "# Query TF:\n",
    "# A dict of word:tf\n",
    "query_tf = {}\n",
    "y = Counter(query)\n",
    "max_occurence = y.most_common(1)[0][1]\n",
    "y = dict(sorted(y.items()))\n",
    "\n",
    "for word,count in y.items():\n",
    "    tf = count/max_occurence\n",
    "    query_tf[word] = tf\n",
    "#print(que)\n",
    "\n",
    "# Query TF-IDF\n",
    "query_tf_idf = np.zeros(len(vocab))\n",
    "\n",
    "for term in query:\n",
    "    q = query_tf[term]\n",
    "    i = idf_dict[term]\n",
    "    query_tf_idf[word_to_ix[term]] = query_tf[term] * idf_dict[term]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5201e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF similarity search\n",
    "\n",
    "\n",
    "sim_dict = {}\n",
    "for doc_id, value in tf_idf.items():\n",
    "    top = np.dot(query_tf_idf, value)\n",
    "    bottom = np.linalg.norm(query_tf_idf) * np.linalg.norm(value)\n",
    "    sim = top/bottom\n",
    "    if sim == 0:\n",
    "        continue\n",
    "    else:\n",
    "        sim_dict.update({doc_id:top/bottom})\n",
    "\n",
    "sim_dict = sorted(sim_dict.items(),reverse=True, key=lambda item: item[1])\n",
    "print(type(sim_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7533e1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NYT_ENG_19950101.0001', 0.1523105228405513),\n",
       " ('NYT_ENG_19950101.0056', 0.029142469066059024),\n",
       " ('NYT_ENG_19950101.0022', 0.028561929187225343),\n",
       " ('NYT_ENG_19950101.0017', 0.016747860911235552)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_dict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadcd248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
